# -*- coding: utf-8 -*-
"""License_plate_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WaFL_XSHzbuvNBYW8wtXDp5xI0uvJSdB

Title: License Plate Recognition Using Deep Learning

# Dataset Source

Dataset Source: US license plates- Image Classification Kaggle (https://www.kaggle.com/datasets/gpiosenka/us-license-plates-image-classification/data)

# The Dataset Analysis

### Installing Kaggle
"""

pip install kaggle

"""### Creating a directory named ".kaggle" in the user's home directory."""

mkdir ~/.kaggle

"""### Coping the file "kaggle.json" to the ".kaggle" directory in the user's home directory"""

! cp kaggle.json ~/.kaggle/

"""### Setting the file permissions of "kaggle.json" in the "/root/.kaggle/" directory to read and write only for the owner."""

! chmod 600 /root/.kaggle/kaggle.json

"""### Downloading the dataset "us-license-plates-image-classification" from Kaggle."""

! kaggle datasets download gpiosenka/us-license-plates-image-classification

"""### Unzipping the file "us-license-plates-image-classification" in the current directory, extracting its contents."""

! unzip us-license-plates-image-classification

"""# The Dataset Analysis

I will be using the new plate dataset for my project because it has been carefully created to achieve accurate training, validation, and testing results. The dataset has undergone a thorough process to remove any duplicate images, missing values and other forms of cleaning.This preserves the highest quality originals. This dataset is specifically extracted from the original dataset, as described in the information provided on Kaggle.

Using the Fastdup for Analysis--- Fastdup is a tool for gaining insights from a large image/video collection
"""

pip install fastdup

"""Using fastdup to gain insight into the new plates datasets"""

import fastdup
fd = fastdup.create(work_dir="/content",
                    input_dir="/content/new plates")
fd.run(ccthreshold=0.9)

fd.summary()

"""Based on the fastdup future summary above, it confirms the information provided on Kaggle about the dataset. The dataset is of high quality, as there are no invalid images, duplicates, missing values, or images clustered into a single component. This indicates that the dataset is clean and does not require any further data cleaning. Now, I will move ahead with preprocessing the data by applying data augmentation techniques.

# Importing Relevant Libraries
"""

# Libraries
!pip install easyocr

import os
from time import time
from tqdm import tqdm
import numpy


import torch
import torch.nn as nn
from torch.nn import Linear, CrossEntropyLoss
from torch.optim import Adam
from torch.utils.data import DataLoader

import torchvision
from torchvision.datasets import ImageFolder
from torchvision.models import resnet18
from torchvision.transforms import transforms
import torchvision.models as models


# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""# Preprocessing Using Data Transformation"""

# Data Transformer
tfm = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=10),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Create Dataset
TRAIN_ROOT = "/content/new plates/train"
TEST_ROOT = "/content/new plates/test"
VAL_ROOT = "/content/new plates/valid"

train_ds = ImageFolder(TRAIN_ROOT, transform=tfm)
test_ds = ImageFolder(TEST_ROOT, transform=tfm)
val_ds = ImageFolder(VAL_ROOT, transform=tfm)

# Length of Train and Test Datasets
LEN_TRAIN = len(train_ds)
LEN_TEST = len(test_ds)
LEN_VAL = len(val_ds)
print(LEN_TRAIN, LEN_TEST, LEN_VAL)

# Index Mapping
print(train_ds.class_to_idx)

# Data Loader
train_loader = DataLoader(train_ds, batch_size = 32, shuffle=True)
test_loader = DataLoader(test_ds, batch_size=32, shuffle = True)
val_loader = DataLoader(val_ds, batch_size=32, shuffle = True)

"""# Model Definition

**Using VGG Model**
"""

import torch
import torch.nn as nn
from torchvision import models
from torch.optim import Adam
from torch.utils.data import DataLoader
from tqdm import tqdm

# Load pre-trained VGG-16 model
model = models.vgg16(weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1)  # Use weights argument

# Replace the output layer with a new fully connected layer for your classification problem
num_classes = 56  # Replace with the number of classes in your problem
model.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)  # Adjust for VGG-16 classifier structure

# Move the model to the desired device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Optimizer
optimizer = Adam(model.parameters(), lr=3e-4, weight_decay=0.0001)

# Loss function
loss_fn = nn.CrossEntropyLoss()

# Training loop
for epoch in range(3):
    start = time()

    tr_acc = 0
    val_acc = 0

    # Train
    model.train()
    with tqdm(train_loader, unit="batch") as tepoch:
        for xtrain, ytrain in tepoch:
            optimizer.zero_grad()

            xtrain = xtrain.to(device)
            ytrain = ytrain.to(device)  # Move target labels to device

            train_prob = model(xtrain)

            loss = loss_fn(train_prob, ytrain)
            loss.backward()
            optimizer.step()

            train_pred = torch.max(train_prob, 1).indices
            tr_acc += int(torch.sum(train_pred == ytrain))

    ep_tr_acc = tr_acc / LEN_TRAIN

    # Evaluate
    model.eval()
    with torch.no_grad():
        for xval, yval in val_loader:
            xval = xval.to(device)
            yval = yval.to(device)  # Move target labels to device

            val_prob = model(xval)

            val_pred = torch.max(val_prob, 1).indices
            val_acc += int(torch.sum(val_pred == yval))

    ep_val_acc = val_acc / LEN_VAL

    end = time()
    duration = (end - start) / 60

    print(f"Epoch: {epoch}, Time: {duration}, Loss: {loss}\nTrain_acc: {ep_tr_acc}, Val_acc: {ep_val_acc}")

"""The VGG model performed poorly after training for three epochs

**Using RestNet18 Model**
"""

# Load the pre-trained ResNet-18 model
model = models.resnet18(pretrained=True)

# Modify the final classification layer to match the number of classes
num_classes = 56
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)

# Freeze all layers except the final classification layer
for name, param in model.named_parameters():
    if "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False

# Move the model to the GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)

"""# Loss Function

Cross-Entropy Loss function, also known as log loss. This function is commonly used for multi-class classification problems. It measures the difference between the predicted probability distribution (output of the model) and the actual probability distribution (one-hot encoded labels).  Minimizing the cross-entropy loss encourages the model to assign higher probabilities to the correct classes.

# Optimizer
Adam optimizer.  Adam is an adaptive learning rate optimization algorithm that can be efficient at updating weights during training.
"""

import torch.optim as optim
from torch.optim.lr_scheduler import StepLR

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()

# Define the optimizer (Adam) and learning rate
optimizer = optim.Adam(model.parameters(), lr=0.1)  # Update the learning rate

# Define the learning rate scheduler
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# Set the number of training epochs
num_epochs = 20

"""# Training loop"""

# Training loop
for epoch in range(num_epochs):
    # Set the model to train mode
    model.train()

    running_loss = 0.0
    running_corrects = 0

    for inputs, labels in train_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        with torch.set_grad_enabled(True):
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = running_corrects.double() / len(train_loader.dataset)


    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

    # Set the model to evaluation mode
    model.eval()

    running_loss = 0.0
    running_corrects = 0

    for inputs, labels in val_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        with torch.no_grad():
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

    epoch_loss = running_loss / len(val_loader.dataset)
    epoch_acc = running_corrects.double() / len(val_loader.dataset)

    print(f"Valid Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")
    print()

    # Adjust learning rate
    scheduler.step()

print("Training complete!")

"""# Result
The Val Accuracy is 0.4607 after 20 Epochs.Hypertuning the parameters is essential to increase the accuracy.

# Hyperparameter Tuning
"""

# Load pre-trained ResNet-18 model
model = models.resnet18(pretrained=True)

# Replace the output layer with a new fully connected layer for your classification problem
num_classes = 56  # Replace with the number of classes in your classification problem
model.fc = Linear(in_features=512, out_features=num_classes)

# Move the model to the desired device (e.g., CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Optimiser
optimiser = Adam(model.parameters(), lr=3e-4, weight_decay=0.0001)

# Loss Function
loss_fn = CrossEntropyLoss()

for epoch in range(3):
    start = time()

    tr_acc = 0
    val_acc = 0

    # Train
    model.train()

    with tqdm(train_loader, unit="batch") as tepoch:
        for xtrain, ytrain in tepoch:
            optimiser.zero_grad()

            xtrain = xtrain.to(device)
            train_prob = model(xtrain)
            train_prob = train_prob.cpu()

            loss = loss_fn(train_prob, ytrain)
            loss.backward()
            optimiser.step()

            # training ends

            train_pred = torch.max(train_prob, 1).indices
            tr_acc += int(torch.sum(train_pred == ytrain))

        ep_tr_acc = tr_acc / LEN_TRAIN

        # Evaluate
        model.eval()
        with torch.no_grad():
            for xval, yval in val_loader:
                xval = xval.to(device)
                val_prob = model(xval)
                val_prob = val_prob.cpu()

                val_pred = torch.max(val_prob, 1).indices
                val_acc += int(torch.sum(val_pred == yval))

        ep_val_acc = val_acc / LEN_VAL

        end = time()
        duration = (end - start) / 60

        print(f"Epoch: {epoch}, Time: {duration}, Loss: {loss}\nTrain_acc: {ep_tr_acc}, Val_acc: {ep_val_acc}")

"""### Evaluation Metrics for HyperParameter Tuning 1"""

import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix

model.eval()
test_acc = 0

test_preds = []
test_labels = []

with torch.no_grad():
    for xtest, ytest in test_loader:
        xtest = xtest.to(device)
        test_prob = model(xtest)
        test_prob = test_prob.cpu()

        test_pred = torch.max(test_prob, 1).indices
        test_preds.extend(test_pred.tolist())
        test_labels.extend(ytest.tolist())
        test_acc += int(torch.sum(test_pred == ytest))

    ep_test_acc = test_acc / LEN_TEST

# Convert the prediction and label lists to numpy arrays
test_preds = np.array(test_preds)
test_labels = np.array(test_labels)

# Calculate metrics
test_precision = precision_score(test_labels, test_preds, average='macro')
test_recall = recall_score(test_labels, test_preds, average='macro')
test_f1score = f1_score(test_labels, test_preds, average='macro')
test_accuracy = accuracy_score(test_labels, test_preds)
test_confusion_matrix = confusion_matrix(test_labels, test_preds)

print("Test Metrics:")
print("Precision:", test_precision)
print("Recall:", test_recall)
print("F1 Score:", test_f1score)
print("Accuracy:", test_accuracy)
print("Confusion Matrix:")
print(test_confusion_matrix)

"""### HyperParameter Tuning 2

Changed the lr=1e-3, weight_decay=0.001
"""

# Load pre-trained ResNet-18 model
model2 = models.resnet18(pretrained=True)

# Replace the output layer with a new fully connected layer for your classification problem
num_classes = 56  # Replace with the number of classes in your classification problem
model.fc = Linear(in_features=512, out_features=num_classes)

# Move the model to the desired device (e.g., CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model2 = model.to(device)

# Optimiser
optimiser = Adam(model.parameters(), lr=1e-3, weight_decay=0.001)

# Loss Function
loss_fn = CrossEntropyLoss()

for epoch in range(3):
    start = time()

    tr_acc = 0
    val_acc = 0

    # Train
    model2.train()

    with tqdm(train_loader, unit="batch") as tepoch:
        for xtrain, ytrain in tepoch:
            optimiser.zero_grad()

            xtrain = xtrain.to(device)
            train_prob = model(xtrain)
            train_prob = train_prob.cpu()

            loss = loss_fn(train_prob, ytrain)
            loss.backward()
            optimiser.step()

            # training ends

            train_pred = torch.max(train_prob, 1).indices
            tr_acc += int(torch.sum(train_pred == ytrain))

        ep_tr_acc = tr_acc / LEN_TRAIN

        # Evaluate
        model2.eval()
        with torch.no_grad():
            for xval, yval in val_loader:
                xval = xval.to(device)
                val_prob = model(xval)
                val_prob = val_prob.cpu()

                val_pred = torch.max(val_prob, 1).indices
                val_acc += int(torch.sum(val_pred == yval))

        ep_val_acc = val_acc / LEN_VAL

        end = time()
        duration = (end - start) / 60

        print(f"Epoch: {epoch}, Time: {duration}, Loss: {loss}\nTrain_acc: {ep_tr_acc}, Val_acc: {ep_val_acc}")

"""### Evaluation Metrics for HyperParameter Tuning 2"""

import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix

model2.eval()
test_acc = 0

test_preds = []
test_labels = []

with torch.no_grad():
    for xtest, ytest in test_loader:
        xtest = xtest.to(device)
        test_prob = model2(xtest)
        test_prob = test_prob.cpu()

        test_pred = torch.max(test_prob, 1).indices
        test_preds.extend(test_pred.tolist())
        test_labels.extend(ytest.tolist())
        test_acc += int(torch.sum(test_pred == ytest))

    ep_test_acc = test_acc / LEN_TEST

# Convert the prediction and label lists to numpy arrays
test_preds = np.array(test_preds)
test_labels = np.array(test_labels)

# Calculate metrics
test_precision = precision_score(test_labels, test_preds, average='macro')
test_recall = recall_score(test_labels, test_preds, average='macro')
test_f1score = f1_score(test_labels, test_preds, average='macro')
test_accuracy = accuracy_score(test_labels, test_preds)
test_confusion_matrix = confusion_matrix(test_labels, test_preds)

print("Test Metrics:")
print("Precision:", test_precision)
print("Recall:", test_recall)
print("F1 Score:", test_f1score)
print("Accuracy:", test_accuracy)
print("Confusion Matrix:")
print(test_confusion_matrix)

"""### HyperParameter Tuning 3

Changed the lr=1e-2, weight_decay=0.01. I changed the optimizer to SGD
"""

# Load pre-trained ResNet-18 model
model3 = models.resnet18(pretrained=True)

# Replace the output layer with a new fully connected layer for your classification problem
num_classes = 56  # Replace with the number of classes in your classification problem
model.fc = Linear(in_features=512, out_features=num_classes)

# Move the model to the desired device (e.g., CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model3 = model.to(device)

# Optimiser
optimiser = optim.SGD(model.parameters(), lr=1e-2, weight_decay=0.01)

# Loss Function
loss_fn = CrossEntropyLoss()

for epoch in range(5):
    start = time()

    tr_acc = 0
    val_acc = 0

    # Train
    model2.train()

    with tqdm(train_loader, unit="batch") as tepoch:
        for xtrain, ytrain in tepoch:
            optimiser.zero_grad()

            xtrain = xtrain.to(device)
            train_prob = model(xtrain)
            train_prob = train_prob.cpu()

            loss = loss_fn(train_prob, ytrain)
            loss.backward()
            optimiser.step()

            # training ends

            train_pred = torch.max(train_prob, 1).indices
            tr_acc += int(torch.sum(train_pred == ytrain))

        ep_tr_acc = tr_acc / LEN_TRAIN

        # Evaluate
        model3.eval()
        with torch.no_grad():
            for xval, yval in val_loader:
                xval = xval.to(device)
                val_prob = model(xval)
                val_prob = val_prob.cpu()

                val_pred = torch.max(val_prob, 1).indices
                val_acc += int(torch.sum(val_pred == yval))

        ep_val_acc = val_acc / LEN_VAL

        end = time()
        duration = (end - start) / 60

        print(f"Epoch: {epoch}, Time: {duration}, Loss: {loss}\nTrain_acc: {ep_tr_acc}, Val_acc: {ep_val_acc}")

"""### Evaluation Metrics for HyperParameter Tuning 3"""

import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix

model3.eval()
test_acc = 0

test_preds = []
test_labels = []

with torch.no_grad():
    for xtest, ytest in test_loader:
        xtest = xtest.to(device)
        test_prob = model3(xtest)
        test_prob = test_prob.cpu()

        test_pred = torch.max(test_prob, 1).indices
        test_preds.extend(test_pred.tolist())
        test_labels.extend(ytest.tolist())
        test_acc += int(torch.sum(test_pred == ytest))

    ep_test_acc = test_acc / LEN_TEST

# Convert the prediction and label lists to numpy arrays
test_preds = np.array(test_preds)
test_labels = np.array(test_labels)

# Calculate metrics
test_precision = precision_score(test_labels, test_preds, average='macro')
test_recall = recall_score(test_labels, test_preds, average='macro')
test_f1score = f1_score(test_labels, test_preds, average='macro')
test_accuracy = accuracy_score(test_labels, test_preds)
test_confusion_matrix = confusion_matrix(test_labels, test_preds)

print("Test Metrics:")
print("Precision:", test_precision)
print("Recall:", test_recall)
print("F1 Score:", test_f1score)
print("Accuracy:", test_accuracy)
print("Confusion Matrix:")
print(test_confusion_matrix)

"""# Conclusion

I was disappointed with the VGG model's performance, so I decided to switch to the Resnet18 model. It's much better than VGG and can achieve more accurate and impressive results.

After Performing Hyperparameter three times, I acheived an accuracy of 0.92

# Testing the Trained Model on New Dataset
"""

import numpy as np
import matplotlib.pyplot as plt

model3.eval()

with torch.no_grad():
    for xtest, ytest in test_loader:
        xtest = xtest.to(device)
        test_prob = model(xtest)
        test_prob = test_prob.cpu()

        test_pred = torch.max(test_prob, 1).indices

        for i in range(len(test_pred)):
            pred_label = test_ds.classes[test_pred[i].item()]
            actual_label = test_ds .classes[ytest[i].item()]

            # Get the corresponding image
            image = xtest[i].cpu().numpy()
            image = np.transpose(image, (1, 2, 0))  # Transpose to (height, width, channels)

            # Display the image and labels
            plt.imshow(image)
            plt.title(f"Predicted: {pred_label}, Actual: {actual_label}")
            plt.axis('off')
            plt.show()

"""# Testing the Model Performance"""

# Test
model3.eval()
test_acc = 0

with torch.no_grad():
    for xtest, ytest in test_loader:
        xtest = xtest.to(device)
        test_prob = model(xtest)
        test_prob = test_prob.cpu()

        test_pred = torch.max(test_prob, 1).indices
        test_acc += int(torch.sum(test_pred == ytest))

    ep_test_acc = test_acc / LEN_TEST

print(f"Test_acc: {ep_test_acc}")

"""After the Hyperparameter Tuning, the accuracy increased significantly. The Test acccuracy is now 0.8857142857142857 which is impressive

#Saving the Model
"""

import torch

# Assuming your model is called 'model'
def save_model(model3, path):
  """
  Saves a PyTorch model to a file.

  Args:
      model: The PyTorch model to save.
      path: The path to save the model file.
  """
  torch.save(model3.state_dict(), path)

# Example usage
model_path = "best_model.pt"
save_model(model3, model_path)

print(f"Model saved to {model_path}")

"""## Model Testing Using Google Images"""

test_loader = DataLoader(test_ds, batch_size=32, shuffle = True)

import requests
from PIL import Image
from io import BytesIO

# Load the pretrained model
model = resnet18(pretrained=False)
model.fc = torch.nn.Linear(512, 56)
model.load_state_dict(torch.load('/content/best_model.pt', map_location=torch.device('cpu')))
model = model.to(device)
model.eval()

# Define the transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Class labels (replace with your actual labels for 56 classes)
class_labels = [
    'ALABAMA', 'ALASKA', 'AMERICAN SAMOA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'CNMI', 'COLORADO', 'CONNECTICUT',
    'DELAWARE', 'FLORIDA', 'GEORGIA', 'GUAM', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY',
    'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA',
    'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA',
    'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',
    'TENNESSEE', 'TEXAS', 'U S VIRGIN ISLANDS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WASHINGTON DC',
    'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'
]

# Function to make predictions
def predict(image):
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        outputs = model(image.to(device))
        _, predicted = torch.max(outputs.data, 1)
        return predicted.item()

# Function to download and process image from URL
def process_image_from_url(image_url):
    response = requests.get(image_url)
    image = Image.open(BytesIO(response.content)).convert('RGB')
    return image

# Example usage
image_url = "https://di-uploads-development.dealerinspire.com/holmanautomotive/uploads/2021/03/Alaska.jpeg"
image = process_image_from_url(image_url)

# Display the image
plt.imshow(image)
plt.axis('off')
plt.show()

prediction = predict(image)
predicted_label = class_labels[prediction]

print("Prediction:", predicted_label)

"""# Testing with another google image"""

image_url = "https://livability.com/wp-content/uploads/2015/06/2015Plate10.jpg.webp"
image = process_image_from_url(image_url)

# Display the image
plt.imshow(image)
plt.axis('off')
plt.show()

prediction = predict(image)
predicted_label = class_labels[prediction]

print("Prediction:", predicted_label)

"""# USing OCR For Character Recognition"""

!pip install easyocr

import torch
from torchvision.transforms import transforms
import torchvision.models as models
import numpy as np
import cv2
from PIL import Image
import easyocr

# Load the pretrained model
model = models.resnet18(pretrained=False)
model.fc = torch.nn.Linear(512, 56)
model.load_state_dict(torch.load('/content/best_model.pt', map_location=torch.device('cpu')))
model.eval()

# Define the transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Class labels (replace with your actual labels for 50 states and 6 districts)
class_labels = [
    'ALABAMA', 'ALASKA', 'AMERICAN SAMOA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'CNMI', 'COLORADO', 'CONNECTICUT',
    'DELAWARE', 'FLORIDA', 'GEORGIA', 'GUAM', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY',
    'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA',
    'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA',
    'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',
    'TENNESSEE', 'TEXAS', 'U S VIRGIN ISLANDS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WASHINGTON DC',
    'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'
]

# Function to make predictions
def predict(image):
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        outputs = model(image)
        _, predicted = torch.max(outputs.data, 1)
        return predicted.item()

# Function to recognize license number
def recognize_license_number(image_path):
        image = cv2.imread(image_path)
        if image is None:
            raise Exception("Failed to read the image file")
        resized_image = cv2.resize(image, (205, 58))
        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)
        _, threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        reader = easyocr.Reader(['en'])
        result = reader.readtext(threshold_image)
        license_number = ''.join([detection[1] for detection in result if detection[2] > 0.5])
        return license_number

# Provide the image path
image_path = '/content/new plates/test/ARIZONA/3.jpg'

# Load the image
image = cv2.imread(image_path)
image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

# Call the function to recognize the license number
prediction = predict(image_pil)
predicted_label = class_labels[prediction]
license_number = recognize_license_number(image_path)

# Display the image
plt.imshow(image)
plt.axis('off')
plt.show()

print("Prediction:", predicted_label)
print("License Number:", license_number)

"""# Testing with Another Image from the Test Dataset"""

# Provide the image path
image_path = '/content/new plates/test/CALIFORNIA/4.jpg'

# Load the image
image = cv2.imread(image_path)
image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

# Call the function to recognize the license number
prediction = predict(image_pil)
predicted_label = class_labels[prediction]
license_number = recognize_license_number(image_path)

# Display the image
plt.imshow(image)
plt.axis('off')
plt.show()

print("Prediction:", predicted_label)
print("License Number:", license_number)

"""# Using Image from Google Search to Test"""

import requests

# Function to download image from URL
def download_image(url, file_path):
    response = requests.get(url)
    with open(file_path, 'wb') as file:
        file.write(response.content)

# Provide the image URL and file path
image_url = 'https://m.media-amazon.com/images/I/610kmpGVixL._AC_UF894,1000_QL80_.jpg'
file_path = '/content/test_image.jpg'  # Update with the desired file path

# Download the image
download_image(image_url, file_path)

# Print success message
print("Image downloaded successfully!")

# Provide the image path
image_path = '/content/test_image.jpg'

# Load the image
image = cv2.imread(image_path)
image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

# Call the function to recognize the license number
prediction = predict(image_pil)
predicted_label = class_labels[prediction]
license_number = recognize_license_number(image_path)

# Display the image
plt.imshow(image)
plt.axis('off')
plt.show()

print("Prediction:", predicted_label)
print("License Number:", license_number)

"""# Model Deployment using Flask"""

pip install flask-ngrok

from google.colab.output import eval_js
print(eval_js("google.colab.kernel.proxyPort(5000)"))

from flask import Flask, render_template, request
from PIL import Image
from flask_ngrok import run_with_ngrok
import torch
from torchvision.transforms import transforms
import torchvision.models as models
import numpy as np
import cv2
import easyocr

app = Flask(__name__, template_folder="/content/templates")

# Load the pretrained model
model = models.resnet18(pretrained=False)
model.fc = torch.nn.Linear(512, 56)
model.load_state_dict(torch.load('/content/best_model.pt', map_location=torch.device('cpu')))
model.eval()

# Define the transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Class labels (replace with your actual labels for 50 states and 6 districts)
class_labels = [
    'ALABAMA', 'ALASKA', 'AMERICAN SAMOA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'CNMI', 'COLORADO', 'CONNECTICUT',
    'DELAWARE', 'FLORIDA', 'GEORGIA', 'GUAM', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY',
    'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA',
    'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA',
    'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'PUERTO RICO', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',
    'TENNESSEE', 'TEXAS', 'U S VIRGIN ISLANDS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WASHINGTON DC',
    'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'
]

# Function to make predictions
def predict(image):
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        outputs = model(image)
        _, predicted = torch.max(outputs.data, 1)
        return predicted.item()

# Function to recognize license number
def recognize_license_number(image_path):
    try:
        image = cv2.imread(image_path)
        if image is None:
            raise Exception("Failed to read the image file")

        resized_image = cv2.resize(image, (205, 58))
        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)
        _, threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        reader = easyocr.Reader(['en'])
        result = reader.readtext(threshold_image)
        license_number = ''.join([detection[1] for detection in result if detection[2] > 0.5])
        return license_number
    except Exception as e:
        return ""

@app.route('/', methods=['GET', 'POST'])
def home():
    if request.method == 'POST':
        if 'file' not in request.files:
            return render_template('index.html', error='No file part')

        file = request.files['file']

        if file.filename == '':
            return render_template('index.html', error='No file selected')

        if file:
            try:
                image_path = file.filename  # Save the uploaded image
                file.save(image_path)
                image = Image.open(image_path)
                prediction = predict(image)  # Call the predict function
                predicted_label = class_labels[prediction]  # Get the predicted label

                # Recognize license number
                license_number = recognize_license_number(image_path)

                # Pass the image path to the template
                return render_template('index.html',
                                       predicted_label=predicted_label,
                                       license_number=license_number,
                                       image_path=image_path)  # Use template name directly
            except Exception as e:
                return render_template('index.html', error=str(e))  # Use template name directly
    return render_template('index.html')  # Use template name directly

if __name__ == '__main__':
    app.run()

"""# Deployment"""

# Index. Html Code

<!DOCTYPE html>
<html>
<head>
    <title>License Plate Classification</title>
    <style>
        body {
            background-color: #f5f5f5;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
        }

        .container {
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
        }

        h1 {
            text-align: center;
            color: #333;
        }

        .upload-section {
            background-color: #fff;
            border-radius: 5px;
            padding: 20px;
            margin-top: 30px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .upload-section p {
            font-size: 16px;
            color: #333;
            margin-bottom: 20px;
        }

        .upload-section input[type="file"] {
            display: none;
        }

        .upload-section label {
            display: block;
            background-color: #4CAF50;
            color: #fff;
            padding: 10px 15px;
            border-radius: 3px;
            cursor: pointer;
        }

        .upload-section .upload-btn {
            text-align: center;
            margin-top: 20px;
        }

        .upload-section .upload-btn button {
            background-color: #333;
            color: #fff;
            padding: 10px 15px;
            border: none;
            border-radius: 3px;
            cursor: pointer;
        }

        .result-section {
            background-color: #fff;
            border-radius: 5px;
            padding: 20px;
            margin-top: 30px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .result-section p {
            font-size: 16px;
            color: #333;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>License Plate Classification</h1>

        <div class="upload-section">
            <p>Upload an image of a license plate to classify the state or district.</p>
            <form method="POST" enctype="multipart/form-data">
                <input type="file" name="file" id="file-upload" accept=".jpg,.jpeg,.png">
                <label for="file-upload">Choose an image...</label>
                <div class="upload-btn">
                    <button type="submit">Predict</button>
                </div>
            </form>
        </div>

        {% if predicted_label or license_number %}
            <div class="result-section">
                {% if predicted_label %}
                    <p>The Predicted State/District: {{ predicted_label }}</p>
                {% endif %}
                {% if license_number %}
                    <p>License Number: {{ license_number }}</p>
                {% endif %}
            </div>
        {% endif %}

        {% if error %}
            <div class="result-section">
                <p>Error: {{ error }}</p>
            </div>
        {% endif %}
    </div>
</body>
</html>